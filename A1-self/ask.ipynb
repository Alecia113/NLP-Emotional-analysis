{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ask.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahKLGXSNfG7R"
      },
      "source": [
        "'''\n",
        "给出原因\n",
        "\n",
        "情感分析： sentiment analysis: [使用RNN recurrent Neural Networks]【lab5】\n",
        "\n",
        "【背景】\n",
        "Lecture5]是对文本的上下文挖掘，它可以识别和提取源材料中的主观信息，帮助企业在监控在线对话的同时，了解其品牌、产品或服务的社会情感。\n",
        "\n",
        "【关注练习】\n",
        "\n",
        "class 要写在下面，面向对象编程\n",
        "【看起来有的学了】\n",
        "\n",
        "'''\n",
        "\n",
        "#预处理： 2分：\n",
        "'''\n",
        "数据集： NLTK's Twitter_Sample dataset 【via APIs】可以查看细节\n",
        "\n",
        "训练和测试都被提供了(testing_data.pkl, training_data.pkl) 可以用A1 template ipynb \n",
        "，可以使用作业1模板(template)ipynb中提供的代码从Google Drive中下载。\n",
        "\n",
        "[要求]\n",
        "  预处理训练集用lab5的几个技术的合集\n",
        "  (e.g. tokenisation, removing numbers, converting to lowercase, removing stop words, stemming, etc.).\n",
        "  要证明为什么要用。#您应该说明您应用特定预处理技术的原因（说明您的决定）。\n",
        "  【看起来有些是不能用的要测试】\n",
        "'''\n",
        "\n",
        "#模块实现 model implementation 7分\n",
        "'''\n",
        "【要做的】\n",
        "  1，word embedding module, 2，Lexicon Embedding module + 3，Bi-directional RNN sequence model\n",
        "\n",
        "  [从lab2,4,5随便选参数]embeddings_dimension ; learning_rate epochs;\n",
        "  [lab5 有模型构建]\n",
        "\n",
        "\n",
        "# word embedding  2分 [lab2]\n",
        "  创建word embedding model(表现word vectors eg: word2vec-CBOW, word2vec-Skip gram, fastText + Glove[lab2])\n",
        "  input embedding of your sequence model\n",
        "  [lab3,4]使用了one-hot vectors 作为inputs 给长序列模型\n",
        "  【要求做的】\n",
        "    1.数据的预处理（word embeddings[lab2;还要做解释说明]） NLTK Twitter dataset ( section 1 提供了) or/and 任何数据集（TED talk , Google News)\n",
        "    2.创建训练模型（for word embeddings) 创建训练模型；需要说清楚超参数【lab2（dimension of embeddings; window size, learning rate,etc.】 \n",
        "        note 任何word embeddings model[lab2] (word2vec-CBOW, word2vec-Skip gram, fasttext, glove)【证明】\n",
        "    3.训练模型： train model\n",
        "\n",
        "#Lexicon embedding 2分 （词典嵌入）\n",
        "  每个单词的积极或者消极的lexicon【从文件夹下载：opinion Lexicaon】(2006 positive and 4783 negative words)\n",
        "  每个单词要被改成： one-dimensional一维分类嵌入，三类。【eg:[not_exist(0), negative(1), positive(2);这个012类别 会在[2.3 的Bi-directional RNN 模型中用到]]\n",
        "  【如果你想用超过一维，或者不使用分类嵌入（categorical） 证明观点】\n",
        "\n",
        "# Bi-directional RNN Sequence Model 3分\n",
        "Many-to-One (N to 1) 建个n to 1 sequence model 为了探测感情（detect sentiment/emotion）你的模型应该是评价中选出的最佳模型（将在第3节评价【evaluation】中讨论）。\n",
        "  【做的】\n",
        "    1.apply/import word + lexicon embedding as input: 你要把训练好的词嵌入和词库嵌入合并起来，并应用到序列模型上    ##不太理解\n",
        "    2.1构建训练Sequence model: 构建Bi-directional RNN-based(Bi-RNN / Bi-LSTM / Bi-GRU) \n",
        "    2.2Many to One (N to 1) sequence model (N: word, One: sentiment- positive or negative)\n",
        "    3.描述超参【证明】【lab4,5】[the number of epochs, learning rate ……]\n",
        "    4.Train model  展示：training loss + number of epochs[lab4,lab5]\n",
        "\n",
        "    【不展示没分】\n",
        "'''\n",
        "\n",
        "#Evaluation 评估  7分\n",
        "\n",
        "'''\n",
        "\n",
        "    训练完模型后；估算两点：\n",
        "    1，Word Embedding Evaluation 【词嵌入估计】\n",
        "    2, Sentiment analysis performance prediction (应用训练模型去测试集)【预测】\n",
        "【要去做】\n",
        "  1.Word Embedding Evaluation 3分\n",
        "    intrinsic evaluation 【lec3 内部估计】 (Semantic-Syntactic word  您需要应用语义-词法关系测试来理解各种关系。)\n",
        "    【eg：https://github.com/Alecia113/NLP-Emotional-analysis/blob/main/README.md】【lab5】\n",
        "    要有个可视结果【table 2 + figure2 #https://nlp.stanford.edu/pubs/glove.pdf 】（Original GloVe Paper : 解释表现)\n",
        "\n",
        "  2.Performance Evaluation 2分 表现估计。\n",
        "    precision 精度，recall, and f1 [lab4]  【解释表现】 #不会这个地方\n",
        "\n",
        "  3.Hyperparameter Testing 2分 \n",
        "      你提供线形图， 展示超参测试。（用测试集+ 解释optimal number of epochs 最佳时期在你选择的学习率上。）\n",
        "      【要有多张图，不同的学习率， （x 应该是 （# of epoch）； y应该是f1】【解释表现】\n",
        "      【不展示没分】\n",
        "'''\n",
        "\n",
        "#Documentation 分类，文件，证明材料 4 分\n",
        "\n",
        "#123 你要描述+ 证明 观点[在规定的标签tag里；您应该说明应用特定技术/模型的目的，并解释其性能。]\n",
        "'''\n",
        "【eg】\n",
        "\n",
        " 对于第1节（预处理数据），您需要在您的ipynb文件中描述进行了哪些预处理技术（删除数字、转换为小写、删除休止符、词干等），\n",
        " 并证明您的决定（选择特定预处理技术的目的，以及使用该技术的好处或为您的AI整合技术）。\n",
        "【目的，好处，】\n",
        "'''\n",
        "\n",
        "#交作业：https://colab.research.google.com/drive/1A6azpUOCUU923JF5B4v7t2pNSzLAQ20t?usp=sharing\n",
        "'''\n",
        "Submit an ipynb file - (file name: your_unikey_COMP5046_Ass1.ipynb) that contains all above sections(Section 1,2,3, and 4).\n",
        "The ipynb template can be found in the Assignment 1 template\n",
        "【改名】\n",
        "【低acc是正常的】\n",
        "【可视化不同测试结果--证明】\n",
        "【训练词嵌入的数据集无所谓。模型的训练：需要的是规定的数据集】\n",
        "自述\n",
        "如果有什么需要用户注意的地方，请在此提及。\n",
        "\n",
        "如果你打算用面向对象的编程风格来实现一个程序，请检查这个ipynb文件的底部。\n",
        "\n",
        "\n",
        "答案是 正如你可以看到ipynb Assingment 1模板中的 \"Read me \"部分，\n",
        "将不同测试结果的比较可视化是一个很好的证明你的决定的方法。\n",
        "你可以找到另一种方法（除了比较不同的模型）--比如显示任何理论上的比较或使用不同的超参数。\n",
        "\n",
        "\n",
        "答：您好。请不要为准确率低而烦恼，因为我们的训练数据集非常小，而你的模型是非常基本的深度学习模型。\n",
        "\n",
        "\n",
        "答：我的答案是 不是的，在讲座5（作业1规范说明）中提到，\n",
        "你可以使用任何数据集（包括TED、Google News）或NLTKtwitter数据集来训练你的单词嵌入。\n",
        "词嵌入只是为了训练词义空间，所以你可以使用任何数据。\n",
        "注意：训练词嵌入与训练用于情感分析的Bi-RNN预测模型不同。\n",
        "对于Bi-RNN情感分析模型的训练，你应该只使用训练数据集（来自我们在作业1模板中提供的NLTK twitter数据集）。\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKIw1XNXfBr1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}